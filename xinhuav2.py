import random
import streamlit as st
from google import genai  # ä½¿ç”¨ç’°å¢ƒä¸­è£å¥½çš„ 1.64.0 ç‰ˆæ­£ç¢ºåŒ¯å…¥æ–¹å¼

# --- 1. å®‰å…¨è®€å– API KEY ---
if "GEMINI_API_KEY" in st.secrets:
    API_KEY = st.secrets["GEMINI_API_KEY"]
else:
    API_KEY = "æ‚¨çš„å‚™ç”¨Key"

# åˆå§‹åŒ– Client (ä¸æŒ‡å®šç‰ˆæœ¬ï¼Œè®“ SDK è‡ªå‹•é©é…ç©©å®šè·¯å¾‘)
client = genai.Client(api_key=API_KEY)

# --- 2. éœæ…‹è³‡æ–™åº« (æ¸›å°‘ Session è¨˜æ†¶é«”è² æ“”) ---
KNOWLEDGE_BASE = {
    "ç¦éŸ³é™ªè«‡": "ã€ç¦éŸ³ 10 æ ¼åœ–ã€‘1.å‰µé€  2.å¢®è½ 3.å¯©åˆ¤ 4.å¾‹æ³• 5.åŸºç£ 6.æ•‘è´– 7.å¾©æ´» 8.ä¿¡å¿ƒ 9.é‡ç”Ÿ 10.æ°¸ç”Ÿã€‚",
    "é–€å¾’è£å‚™": "ã€é–€å¾’ 12 æ ¼åœ–ã€‘1.ç”Ÿå‘½ä¸»æ¬Š 2.è®€ç¶“éˆä¿® 3.ç¦±å‘Šç”Ÿæ´» 4.åœ˜å¥‘ç”Ÿæ´» 5.è–æ½”ç”Ÿæ´» 6.è¦‹è­‰åˆ†äº« 7.äº‹å¥‰äººç”Ÿ 8.å¥‰ç»ç”Ÿæ´» 9.å±¬éˆçˆ­æˆ° 10.å¤§ä½¿å‘½ 11.è‚¢é«”é€£çµ 12.æ°¸æ†ç›¼æœ›ã€‚",
    "æ–°æœ‹å‹å°è¦½": "ã€æ•™æœƒè³‡è¨Šã€‘èšæœƒæ™‚é–“é€±æ—¥ä¸Šåˆ 09:30ã€‚åœ°é»åœ¨å°å—å¸‚æ–°åŒ–å€ï¼Œæ­¡è¿æ–°æœ‹å‹ã€‚"
}

DETAILED_PROMPTS = {
    "ç¦éŸ³é™ªè«‡": "ä½ ç¾åœ¨æ˜¯ã€æ–°åŒ–æ•™æœƒ-ç¦éŸ³é™ªè«‡è€…ã€ã€‚èªæ°£æº«æŸ”çœŸèª ï¼Œè«‹ç”¨æº«å’Œçš„å£å»å›ç­”å•é¡Œã€‚",
    "æ–°æœ‹å‹å°è¦½": "ä½ ç¾åœ¨æ˜¯ã€æ–°åŒ–æ•™æœƒ-æ•¸ä½æ¥å¾…å“¡ã€ã€‚ç†±æƒ…å¼•å°æ–°æœ‹å‹äº†è§£æ•™æœƒã€‚",
    "é–€å¾’è£å‚™": "ä½ ç¾åœ¨æ˜¯ã€æ–°åŒ–æ•™æœƒ-é–€å¾’è£å‚™åŠ©æ‰‹ã€ã€‚é¼“å‹µä¿¡å¾’æ‰æ ¹çœŸç†ã€‚"
}

# --- 3. å´é‚Šæ¬„è¨­è¨ˆ ---
with st.sidebar:
    st.image("https://images.unsplash.com/photo-1438232992991-995b7058bbb3?q=80&w=1000", caption="æ–°åŒ–é•·è€æ•™æœƒ")
    st.title("â›ª æœäº‹é¸å–®")
    role_choice = st.radio("é¸æ“‡æ¨¡å¼ï¼š", list(DETAILED_PROMPTS.keys()), key="role_radio")
    
    st.markdown("---")
    st.info(f"æ¨¡å¼ï¼š**{role_choice}**")
    st.warning("âš ï¸ ç³»çµ±ä¸æœƒè¨˜éŒ„æ‚¨çš„è©¢å•ï¼Œä¿è­·éš±ç§ã€‚")

# --- 4. ä¸»é é¢æ¸²æŸ“ ---
st.markdown(f"### â›ª ç›®å‰æ¨¡å¼ï¼š{role_choice}")
st.write("è«‹åœ¨ä¸‹æ–¹è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œæ•¸ä½åŒå·¥å°‡ç«­èª ç‚ºæ‚¨æœå‹™ã€‚")
st.markdown("---")

# --- 5. å°è©±é‚è¼¯ (å–®æ¬¡å•ç­”ï¼šæœ€ç©©ã€çœéŒ¢ã€ä¸ç•™ç´€éŒ„) ---

user_input = st.chat_input("è«‹åœ¨æ­¤è¼¸å…¥æ‚¨çš„å•é¡Œ...")

if user_input:
    # é¡¯ç¤ºä½¿ç”¨è€…ç•¶å‰å•é¡Œ
    with st.chat_message("user"):
        st.write(user_input)

    with st.chat_message("assistant"):
        with st.spinner("åŒå·¥æ­£åœ¨æ€è€ƒä¸­..."):
            try:
                # ã€æ¢å¾©æ ¸å¿ƒç©©å®šæ€§ï¼šåˆä½µæŒ‡ä»¤æ³•ã€‘
                # å°‡èº«åˆ†è¨­å®šèˆ‡çŸ¥è­˜åº«ç›´æ¥ä½µå…¥ Promptï¼Œé¿é–‹ system_instruction åƒæ•¸å ±éŒ¯
                prompt_combined = f"æŒ‡ä»¤ï¼š{DETAILED_PROMPTS[role_choice]}\nèƒŒæ™¯çŸ¥è­˜ï¼š{KNOWLEDGE_BASE[role_choice]}\n\nå•é¡Œï¼š{user_input}"
                
                # contents åƒ…åŒ…å«ç•¶å‰çµ„åˆå¥½çš„æ–‡å­—ï¼Œé”æˆã€Œä¸ä¿ç•™ç´€éŒ„ã€ä¸”ã€Œç¯€çœ API è€—æã€
                response = client.models.generate_content(
                    model="gemini-1.5-flash", 
                    contents=[prompt_combined],
                    config={
                        "temperature": 0.7,
                        "max_output_tokens": 400, # ç¯€çœæ¶ˆè€—ï¼šé™åˆ¶å›è¦†é•·åº¦
                        "top_p": 0.95
                    }
                )

                if response and response.text:
                    st.markdown(f"### {response.text}")
                
            except Exception as e:
                # çµ¦äºˆç°¡æ½”æç¤ºï¼Œä¸è®“å ±éŒ¯åš‡åˆ°ä½¿ç”¨è€…
                st.error("é€£ç·šç›®å‰è¼ƒç‚ºå¿™ç¢Œï¼Œè«‹é‡æ–°è¼¸å…¥ä¸€æ¬¡ã€‚")
                with st.expander("é™¤éŒ¯è³‡è¨Š (é–‹ç™¼è€…åƒè€ƒ)"):
                    st.code(str(e))
else:
    st.write("ğŸ™ å¹³å®‰ï¼è«‹å•ä»Šå¤©æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«æ‚¨çš„å—ï¼Ÿ")
