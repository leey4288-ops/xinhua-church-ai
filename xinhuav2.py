import random
import streamlit as st
from google import genai

# --- 1. å®‰å…¨è®€å– API KEY ---
if "GEMINI_API_KEY" in st.secrets:
    API_KEY = st.secrets["GEMINI_API_KEY"]
else:
    API_KEY = "æ‚¨çš„å‚™ç”¨Key"

# åˆå§‹åŒ– Client (1.64.0 ç‰ˆå»ºè­°å¯«æ³•)
client = genai.Client(api_key=API_KEY)

# --- 2. éœæ…‹è³‡æ–™åº« (æ¸›å°‘ Session è¨˜æ†¶é«”è² æ“”) ---
BIBLE_VERSES = [
    "ã€Œæ‡‰ç•¶ä¸€ç„¡æ›æ…®...ã€â€” è…“ç«‹æ¯”æ›¸ 4:6",
    "ã€Œä½ çš„è©±æ˜¯æˆ‘è…³å‰çš„ç‡ˆ...ã€â€” è©©ç¯‡ 119:105",
    "ã€Œè€¶å’Œè¯æ˜¯æˆ‘çš„ç‰§è€…ï¼Œæˆ‘å¿…ä¸è‡´ç¼ºä¹ã€‚ã€â€” è©©ç¯‡ 23:1"
]

KNOWLEDGE_BASE = {
    "ç¦éŸ³é™ªè«‡": "ã€ç¦éŸ³ 10 æ ¼åœ–ã€‘1.å‰µé€ ...10.æ°¸ç”Ÿã€‚",
    "é–€å¾’è£å‚™": "ã€é–€å¾’ 12 æ ¼åœ–ã€‘1.ç”Ÿå‘½ä¸»æ¬Š...12.æ°¸æ†ç›¼æœ›ã€‚",
    "æ–°æœ‹å‹å°è¦½": "ã€æ•™æœƒè³‡è¨Šã€‘èšæœƒæ™‚é–“é€±æ—¥ä¸Šåˆ 09:30ã€‚"
}

DETAILED_PROMPTS = {
    "ç¦éŸ³é™ªè«‡": "ä½ ç¾åœ¨æ˜¯ã€æ–°åŒ–æ•™æœƒ-ç¦éŸ³é™ªè«‡è€…ã€ã€‚èªæ°£æº«æŸ”ã€‚",
    "æ–°æœ‹å‹å°è¦½": "ä½ ç¾åœ¨æ˜¯ã€æ–°åŒ–æ•™æœƒ-æ•¸ä½æ¥å¾…å“¡ã€ã€‚ç†±æƒ…å¼•å°ã€‚",
    "é–€å¾’è£å‚™": "ä½ ç¾åœ¨æ˜¯ã€æ–°åŒ–æ•™æœƒ-é–€å¾’è£å‚™åŠ©æ‰‹ã€ã€‚é¼“å‹µæˆé•·ã€‚"
}

# --- 3. å´é‚Šæ¬„ ---
with st.sidebar:
    st.image("https://images.unsplash.com/photo-1438232992991-995b7058bbb3?q=80&w=1000")
    role_choice = st.radio("é¸æ“‡æ¨¡å¼ï¼š", list(DETAILED_PROMPTS.keys()), key="role_radio")
    st.info(f"æ¨¡å¼ï¼š**{role_choice}**")
    st.warning("âš ï¸ ç³»çµ±ä¸æœƒè¨˜éŒ„æ‚¨çš„è©¢å•ï¼Œé—œé–‰å¾Œç´€éŒ„å³æ¶ˆå¤±ã€‚")

# --- 4. ä¸»ç•«é¢æ¸²æŸ“ ---
st.markdown(f"### ğŸ“– ä»Šæ—¥é‡‘å¥ï¼š\n> {random.choice(BIBLE_VERSES)}")
st.markdown("---")

# --- 5. å°è©±é‚è¼¯ (å–®æ¬¡å•ç­” + ä¿®æ­£ 404) ---

# ä½¿ç”¨æ–‡å­—è¼¸å…¥æ¡†
user_input = st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...")

if user_input:
    # é¡¯ç¤ºä½¿ç”¨è€…ç•¶å‰å•é¡Œ
    with st.chat_message("user"):
        st.write(user_input)

    with st.chat_message("assistant"):
        with st.spinner("åŒå·¥æ­£åœ¨æ€è€ƒä¸­..."):
            try:
                # åˆä½µæŒ‡ä»¤èˆ‡å•é¡Œï¼Œé€™æ˜¯ä¸å ±éŒ¯ã€ä¸ç•™æ­·å²ç´€éŒ„çš„æœ€ä½³åšæ³•
                full_prompt = f"æŒ‡ä»¤ï¼š{DETAILED_PROMPTS[role_choice]}\nçŸ¥è­˜åº«ï¼š{KNOWLEDGE_BASE[role_choice]}\n\nå•é¡Œï¼š{user_input}"

                # ã€é—œéµä¿®æ­£ã€‘ä½¿ç”¨å®Œæ•´çš„æ¨¡å‹è·¯å¾‘ models/gemini-1.5-flash
                # é€™èƒ½è§£æ±º API v1 æ‰¾ä¸åˆ°æ¨¡å‹çš„ 404 å•é¡Œ
                response = client.models.generate_content(
                    model="models/gemini-1.5-flash",
                    contents=[full_prompt],
                    config={
                        "temperature": 0.7,
                        "max_output_tokens": 400,  # ç¯€çœ API è€—æï¼šé™åˆ¶å­—æ•¸
                        "top_p": 0.95
                    }
                )

                if response and response.text:
                    st.markdown(f"### {response.text}")

            except Exception as e:
                st.error("é€£ç·šç•°å¸¸ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
                with st.expander("è©³ç´°å ±éŒ¯ (é™¤éŒ¯ç”¨)"):
                    st.code(str(e))
else:
    st.write("ğŸ™ å¹³å®‰ï¼æˆ‘æ˜¯æ•™æœƒæ•¸ä½åŒå·¥ï¼Œè«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å¹«æ‚¨çš„å—ï¼Ÿ")